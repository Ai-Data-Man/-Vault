---
{"dg-publish":true,"permalink":"/卡片/百万消息在消息队列里积压.mp4/","dgPassFrontmatter":true}
---

[百万消息在消息队列里积压.mp4](file:///Z:%5C我的阅读黑曜石Vault%5C资产库藏%5C互联网Java工程师面试突击训练系列课程%5C第一季%5C10_完了！生产事故！几百万消息在消息队列里积压了几个小时！%5C视频.mp4)
* [[Logseq元问题库/pages/？解决消息队列的延时及过期失效问题？处理消息已满的消息队列？处理持续积压几小时的百万级消息\|？解决消息队列的延时及过期失效问题？处理消息已满的消息队列？处理持续积压几小时的百万级消息]]
	* 这些问题本质都是消费端出现了问题, 不消费了或是消费缓慢，然后出现了消息积压，随着时间增长依次将可能出现以下结果为：消息存储超过了设置的消息过期时间而失效->积压时间过长->磁盘写满
	*  [[Logseq元问题库/pages/？消息积压过期失效的处理方法\|？消息积压过期失效的处理方法]]
		* 消息积压过期失效，其实意味着没啥积压，此时问题的重点在于消息丢失。只能 #消息批量重导
	* [[Logseq元问题库/pages/？消息积压时间过长的处理方法\|？消息积压时间过长的处理方法]]
		* 如果你积压了几百万到上千万的数据，即使消费者恢复了，也需要过长的时间才能恢复过来。因此一般这个时候，只能临时紧急扩容：<label class="ob-comment" title="" style=""> 关键词，修正、增加、分发。在于先出修正了消费速率的新版consumer，然后临时额外增加队列相关和新版consummer资源，旧版consumer改为分发用的consumer <input type="checkbox"> <span style=""> Comment </span></label>
			* 先修复consumer的问题，确保其恢复消费速度，然后将现有cnosumer都停掉
			* 新建一个topic，partition是原来的10倍，临时建立好原先10倍或者20倍的queue数量
			* 然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的10倍数量的queue
			* 接着临时征用10倍的机器来部署consumer，每一批consumer消费一个临时queue的数据
			* 这种做法相当于是临时将queue资源和consumer资源扩大10倍，以正常的10倍速度来消费数据
			* 等快速消费完积压数据之后，得恢复原先部署架构，重新用原先的consumer机器来消费消息
	* [[Logseq元问题库/pages/？消息积压磁盘写满的处理方法\|？消息积压磁盘写满的处理方法]]
		* 只能丢弃 #消息队列 的消息，然后 #消息批量重导

---
{"dg-publish":true,"permalink":"/日记/2023-09-06/","dgPassFrontmatter":true}
---

<< [[日记/2023-09-05\|2023-09-05]] | [[日记/2023-09-07\|2023-09-07]] >>
## 🕓今日主题
* [[卡片/哔哩哔哩-花了两万买的Java面试合集-周瑜老师\|哔哩哔哩-花了两万买的Java面试合集-周瑜老师]]
	* [[卡片/P112.54、什么是服务雪崩？什么是服务限流？\|P112.54、什么是服务雪崩？什么是服务限流？]]
		* [00:00](http://localhost:5244/d/%E6%88%91%E7%9A%84%E5%BA%A6%E7%9B%98/%E8%A7%86%E9%A2%91/%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9-%E8%8A%B1%E4%BA%86%E4%B8%A4%E4%B8%87%E4%B9%B0%E7%9A%84Java%E9%9D%A2%E8%AF%95%E5%90%88%E9%9B%86-%E5%91%A8%E7%91%9C%E8%80%81%E5%B8%88/P112.54%E3%80%81%E4%BB%80%E4%B9%88%E6%98%AF%E6%9C%8D%E5%8A%A1%E9%9B%AA%E5%B4%A9%EF%BC%9F%E4%BB%80%E4%B9%88%E6%98%AF%E6%9C%8D%E5%8A%A1%E9%99%90%E6%B5%81%EF%BC%9F.mp4#t=0)
		* [[Logseq元知识库/pages/服务雪崩\|服务雪崩]]
			* 假如服务A调用服务B，服务B调用服务C，突然A接收到大量请求，假如服务A本身可以抗住这些请求，可是C扛不住，导致C请求堆积，进而服务B请求堆积，从而服务A不可用。这种因为局部服务崩调传导而导致全局崩掉的情况，就叫服务雪崩。解决办法是[[Logseq元知识库/pages/服务降级\|服务降级]]和[[Logseq元知识库/pages/服务熔断\|服务熔断]]
		* [[Logseq元知识库/pages/服务限流\|服务限流]]
			* 高并发场景下为对服务的请求数设置上限，保护服务，防止系统被压垮。在秒杀场景下，[[Logseq元知识库/pages/服务限流\|服务限流]] 很重要
	* [[卡片/P113.55、什么是服务熔断？什么是服务降级？区别是什么？\|P113.55、什么是服务熔断？什么是服务降级？区别是什么？]]
		* [00:00](http://localhost:5244/d/%E6%88%91%E7%9A%84%E5%BA%A6%E7%9B%98/%E8%A7%86%E9%A2%91/%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9-%E8%8A%B1%E4%BA%86%E4%B8%A4%E4%B8%87%E4%B9%B0%E7%9A%84Java%E9%9D%A2%E8%AF%95%E5%90%88%E9%9B%86-%E5%91%A8%E7%91%9C%E8%80%81%E5%B8%88/P113.55%E3%80%81%E4%BB%80%E4%B9%88%E6%98%AF%E6%9C%8D%E5%8A%A1%E7%86%94%E6%96%AD%EF%BC%9F%E4%BB%80%E4%B9%88%E6%98%AF%E6%9C%8D%E5%8A%A1%E9%99%8D%E7%BA%A7%EF%BC%9F%E5%8C%BA%E5%88%AB%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F.mp4#t=0)
		* [[Logseq元知识库/pages/服务熔断\|服务熔断]]
			* 下游服务B不可用时，上游服务A不再调用下游服务B，而是直接返回一个结果，以减轻服务A和B的压力，直到服务B恢复
		* [[Logseq元知识库/pages/服务降级\|服务降级]] 
			* 系统压力过载时，把某个[[Logseq元知识库/pages/服务限流\|服务限流]] 或者关闭来减轻系统压力 
		* [[Logseq元问题库/pages/？服务熔断 与 服务降级 的异同\|？服务熔断 与 服务降级 的异同]]
			* 异
				* 熔断是被动的，是下游服务故障触发
				* 降级是主动的，是为了减轻系统负载所做的决策
			* 同
				* 目的都是防止系统崩溃
				* 都让用户体验到某些功能不可用
	* [[卡片/P114.56、SOA、分布式、微服务之间有什么关系和区别？\|P114.56、SOA、分布式、微服务之间有什么关系和区别？]]
		* [00:00](http://localhost:5244/d/%E6%88%91%E7%9A%84%E5%BA%A6%E7%9B%98/%E8%A7%86%E9%A2%91/%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9-%E8%8A%B1%E4%BA%86%E4%B8%A4%E4%B8%87%E4%B9%B0%E7%9A%84Java%E9%9D%A2%E8%AF%95%E5%90%88%E9%9B%86-%E5%91%A8%E7%91%9C%E8%80%81%E5%B8%88/P114.56%E3%80%81SOA%E3%80%81%E5%88%86%E5%B8%83%E5%BC%8F%E3%80%81%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%B9%8B%E9%97%B4%E6%9C%89%E4%BB%80%E4%B9%88%E5%85%B3%E7%B3%BB%E5%92%8C%E5%8C%BA%E5%88%AB%EF%BC%9F.mp4#t=0)
		* [[Logseq元知识库/pages/分布式⁰架构⁰\|分布式⁰架构⁰]]
			* 将[[Logseq元知识库/pages/单体⁰架构⁰\|单体⁰架构⁰]]中的各部分拆分，然后部署到不同的机器或进程中去
		* [[Logseq元知识库/pages/SOA⁰\|SOA⁰]]
			* 是一种面向服务、中心化的 #分布式⁰架构⁰ ，系统所有服务都注册在总线上(总线是架构中心)，当调用服务时，从总线查找服务信息然后调用。
		* [[Logseq元知识库/pages/微服务⁰架构⁰\|微服务⁰架构⁰]]
			* 是一种彻底面向服务的、去中心化的 #分布式⁰架构⁰  。把系统各个功能抽成一个个小的应用程序，一个应用程序对应一个服务。
		* [[Logseq元问题库/pages/？SOA 分布式架构 微服务架构 的区别与联系\|？SOA 分布式架构 微服务架构 的区别与联系]]
			* [[Logseq元知识库/pages/SOA⁰\|SOA⁰]] [[Logseq元知识库/pages/微服务⁰架构⁰\|微服务⁰架构⁰]] 都属于[[Logseq元知识库/pages/分布式⁰架构⁰\|分布式⁰架构⁰]] 
			* [[Logseq元知识库/pages/微服务⁰架构⁰\|微服务⁰架构⁰]] 去中心化 ，因此比 [[Logseq元知识库/pages/SOA⁰\|SOA⁰]]  更加彻底的面向服务：比如[[Logseq元知识库/pages/微服务⁰架构⁰\|微服务⁰架构⁰]] 虽然有个注册中心，但不同于[[Logseq元知识库/pages/SOA⁰\|SOA⁰]] 总线，即使注册中心挂了，在相当一段时间，微服务之间的调用还是不会受影响的
	* [[卡片/P115.57、BIO、NIO、AIO分别是什么\|P115.57、BIO、NIO、AIO分别是什么]]
		* [00:00](http://localhost:5244/d/%E6%88%91%E7%9A%84%E5%BA%A6%E7%9B%98/%E8%A7%86%E9%A2%91/%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9-%E8%8A%B1%E4%BA%86%E4%B8%A4%E4%B8%87%E4%B9%B0%E7%9A%84Java%E9%9D%A2%E8%AF%95%E5%90%88%E9%9B%86-%E5%91%A8%E7%91%9C%E8%80%81%E5%B8%88/P115.57%E3%80%81BIO%E3%80%81NIO%E3%80%81AIO%E5%88%86%E5%88%AB%E6%98%AF%E4%BB%80%E4%B9%88.mp4#t=0)
		* [[Logseq元知识库/pages/BIO\|BIO]]
			* [[Logseq元知识库/pages/BIO\|BIO]] 读取数据会阻塞，且线程需要通过它来主动查询是否有数据可读
		* [[Logseq元知识库/pages/NIO\|NIO]]
			* [[Logseq元知识库/pages/NIO\|NIO]] 需要主动的去查询是否有IO事件
		* [[Logseq元知识库/pages/AIO\|AIO]]
			* [[Logseq元知识库/pages/NIO\|NIO]] 2.0，异步 非[[Logseq元知识库/pages/阻塞\|阻塞]] 的[[Logseq元知识库/pages/IO.接口\|IO.接口]] 
			* 数据可读时会通知线程，无需线程主动查询
	* [[卡片/P116.58、零拷贝是什么\|P116.58、零拷贝是什么]]
		* [00:00](http://localhost:5244/d/%E6%88%91%E7%9A%84%E5%BA%A6%E7%9B%98/%E8%A7%86%E9%A2%91/%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9-%E8%8A%B1%E4%BA%86%E4%B8%A4%E4%B8%87%E4%B9%B0%E7%9A%84Java%E9%9D%A2%E8%AF%95%E5%90%88%E9%9B%86-%E5%91%A8%E7%91%9C%E8%80%81%E5%B8%88/P116.58%E3%80%81%E9%9B%B6%E6%8B%B7%E8%B4%9D%E6%98%AF%E4%BB%80%E4%B9%88.mp4#t=0)
		* [[Logseq元知识库/pages/零拷贝⁰\|零拷贝⁰]]
			* 零拷贝⁰是一种高效的[[Logseq元知识库/pages/IO\|IO]] 操作优化技术，通过减少或避免数据的拷贝，从而可以减少CPU的上下文切换及拷贝时间开销。
			* 背景示例
				* 一个很好的过多数据拷贝的示例就是读取文件，然后通过socket网络传输：
				![quicker_59a20244-60ef-4e27-b819-4aabbae3b8fa.png](/img/user/Logseq%E5%85%83%E9%97%AE%E9%A2%98%E5%BA%93/assets/quicker_59a20244-60ef-4e27-b819-4aabbae3b8fa.png)
					* 我们为了完成读文件传输操作而写的代码，一共发生了 4 次 #用户态⁰  与 #内核态⁰  的上下文切换, 并且有两次 #DMA⁰  硬件拷贝，和两次 #CPU⁰   拷贝
					* 所以[[Logseq元知识库/pages/零拷贝⁰\|零拷贝⁰]] 常见的一个实现思路就是应用程序直接把内核中的一块区域（缓冲区）转移到另一块内核区域（ [[Logseq元知识库/pages/Socket⁰\|Socket⁰]]  缓冲区），而不经过中间  #用户态⁰ 的用户缓存区。
	* [[卡片/P117.59、Netty是什么？和Tomcat有什么区别？特点是什么？\|P117.59、Netty是什么？和Tomcat有什么区别？特点是什么？]]
		* [00:00](http://localhost:5244/d/%E6%88%91%E7%9A%84%E5%BA%A6%E7%9B%98/%E8%A7%86%E9%A2%91/%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9-%E8%8A%B1%E4%BA%86%E4%B8%A4%E4%B8%87%E4%B9%B0%E7%9A%84Java%E9%9D%A2%E8%AF%95%E5%90%88%E9%9B%86-%E5%91%A8%E7%91%9C%E8%80%81%E5%B8%88/P117.59%E3%80%81Netty%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%E5%92%8CTomcat%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%EF%BC%9F%E7%89%B9%E7%82%B9%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F.mp4#t=0)
		* [[Logseq元知识库/pages/Netty\|Netty]]
			* 0|[[Logseq元知识库/pages/Netty\|Netty]]是一个基于[[Logseq元知识库/pages/NIO\|NIO]]]] 的异步事件驱动的网络通信框架，性能好，封装了原生[[Logseq元知识库/pages/NIO\|NIO]] 的复杂性，提供了简单易用的API来开发高性能的网络服务器 
			* 2|特点 
				* 高性能 
				* 高扩展，高定制性 
				* 易用性
				* 异步，NIO
		* [[Logseq元知识库/pages/Tomcat\|Tomcat]]
			* [[Logseq元知识库/pages/Tomcat\|Tomcat]]是一个基于Java的开源Web服务器，是一个[[Logseq元知识库/pages/Servelet\|Servelet]][[Logseq元知识库/pages/容器\|容器]] 。
		* [[Logseq元知识库/pages/Netty\|Netty]]||[[Logseq元知识库/pages/Tomcat\|Tomcat]] 
			* 1|[[Logseq元知识库/pages/Netty\|Netty]]不受协议限制定制性强，因 [[Logseq元知识库/pages/Netty\|Netty]] 封装的是底层的[[Logseq元知识库/pages/IO\|IO]]模型，关注的是网路数据的传输和处理，而不关心具体的协议。[[Logseq元知识库/pages/Tomcat\|Tomcat]] 作为[[Logseq元知识库/pages/Servelet\|Servelet]] 容器，基本上只运行[[Logseq元知识库/pages/Servelet\|Servelet]] 程序，并处理http请求
	* [[卡片/P118.60、Netty的线程模型是怎么样的\|P118.60、Netty的线程模型是怎么样的]]
		* 0|[00:00](http://localhost:5244/d/%E6%88%91%E7%9A%84%E5%BA%A6%E7%9B%98/%E8%A7%86%E9%A2%91/%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9-%E8%8A%B1%E4%BA%86%E4%B8%A4%E4%B8%87%E4%B9%B0%E7%9A%84Java%E9%9D%A2%E8%AF%95%E5%90%88%E9%9B%86-%E5%91%A8%E7%91%9C%E8%80%81%E5%B8%88/P118.60%E3%80%81Netty%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B%E6%98%AF%E6%80%8E%E4%B9%88%E6%A0%B7%E7%9A%84.mp4#t=0)
		*  1|[[Logseq元问题库/pages/？？Netty代码示例\|？？Netty代码示例]]	
			* 0|[[Logseq元知识库/pages/NioEventLoopGroup\|NioEventLoopGroup]]
				* [[Logseq元知识库/pages/Netty\|Netty]] [[Logseq元知识库/pages/NIO\|NIO]]线程模型的核心组件。它是一个线程池，包含一组[[Logseq元知识库/pages/NioEventLoop\|NioEventLoop]] ，用于处理[[Logseq元知识库/pages/IO\|IO]]操作，如接受新连接、接受数据、发送数据等
			* 1|[[Logseq元知识库/pages/NioEventLoop\|NioEventLoop]]
				* [[Logseq元知识库/pages/Netty\|Netty]] [[Logseq元知识库/pages/NIO\|NIO]]线程，包含一个不断循环执行的任务，一个[[Logseq元知识库/pages/NioEventLoop\|NioEventLoop]]可以处理多个Channel的[[Logseq元知识库/pages/IO\|IO]]事件
			* 2|[[Logseq元知识库/pages/BossGroup\|BossGroup]]
				* 是一个[[Logseq元知识库/pages/NioEventLoopGroup\|NioEventLoopGroup]]实例，但一般只设置一个[[Logseq元知识库/pages/NioEventLoop\|NioEventLoop]]并处理[[Logseq元知识库/pages/ServerSocketChannel\|ServerSocketChannel]]上的客户端连接事件而不会执行具体的[[Logseq元知识库/pages/IO\|IO]]操作，却是把连接事件分发给[[Logseq元知识库/pages/WorkerGroup\|WorkerGroup]]中的[[Logseq元知识库/pages/NioEventLoop\|NioEventLoop]]来处理
			* 3|[[Logseq元知识库/pages/WorkerGroup\|WorkerGroup]]
				* 是一个[[Logseq元知识库/pages/NioEventLoopGroup\|NioEventLoopGroup]]实例，一般设置多个[[Logseq元知识库/pages/NioEventLoop\|NioEventLoop]]，用于处理[[Logseq元知识库/pages/SocketChannel\|SocketChannel]]上的[[Logseq元知识库/pages/IO\|IO]]事件并执行[[Logseq元知识库/pages/IO\|IO]]操作
		* 2|[[Logseq元问题库/pages/？Web请求处理模型\|？Web请求处理模型]]
			* 0|第一种方向是[[Logseq元知识库/pages/基于线程的架构\|基于线程的架构]]
				* [[Logseq元知识库/pages/基于线程的架构\|基于线程的架构]] 
					* 0|基本思路就是多线程并发模式，每个请求都会使用一个线程处理
					  ![Pasted image 20230727111655.png](/img/user/Logseq%E5%85%83%E9%97%AE%E9%A2%98%E5%BA%93/assets/Pasted%20image%2020230727111655.png)
					* 1|优点
						* 简单，易于理解，便于调试与开发
						* 提高了吞吐量。原因：
							* 一个请求阻塞，不会影响其他请求
					* 2|缺点
						* 不适合并发大的场景。原因：
							* 线程需要占用资源，线程数有限，线程数过多会导致资源耗尽
							* 创建和销毁线程需要代价，如时间。但这一点可以通过使用线程池来缓解
							* 操作系统多线程处理存在上下文切换、调度等开销
							* 线程处理IO，等待输入或输出的时间处于空闲，浪费CPU资源
					* 3|综合优点和缺点，我们可以确定[[Logseq元知识库/pages/基于线程的架构\|基于线程的架构]]特别适合请求并发量不大同时计算密集的场景
			* 1|第二种方向是[[Logseq元知识库/pages/事件驱动架构\|事件驱动架构]]
				* [[Logseq元知识库/pages/事件驱动架构\|事件驱动架构]] 
					* 0|分析一下[[Logseq元知识库/pages/基于线程的架构\|基于线程的架构]]不适用并发大场景的原因，想要适用并发大的场景，有一个很重要的可改进的地方就是线程等待IO。很自然就可以想到等待IO时，线程可以先退出请求处理，等到IO完成再继续请求处理。显然，需要一个机制来通知线程IO已经完成，这个机制运用了[[Logseq元知识库/pages/事件驱动\|事件驱动]]。
						* [[Logseq元知识库/pages/事件驱动\|事件驱动]]
							* 0|事件驱动是从[[Logseq元知识库/pages/发布订阅模式\|发布订阅模式]]借鉴过来的，是一种编程思想或编程模型 
								* [[Logseq元知识库/pages/发布订阅模式\|发布订阅模式]]
									* 0|![quicker_4bfbfee4-bba9-4fa5-91bc-7084021aaefc.png](/img/user/Logseq%E5%85%83%E9%97%AE%E9%A2%98%E5%BA%93/assets/quicker_4bfbfee4-bba9-4fa5-91bc-7084021aaefc.png)
									* 1|从[[Logseq元知识库/pages/观察者模式\|观察者模式]] 演进而来
										* [[Logseq元知识库/pages/观察者模式\|观察者模式]]
											* 0|![20230727_083803.png](/img/user/Logseq%E5%85%83%E9%97%AE%E9%A2%98%E5%BA%93/assets/20230727_083803.png)
											* 1|涉及两个角色：观察者和被观察者。被观察者持有主题(就是状态)，被观察者还持有观察者的引用，当被观察者主题发生变化时，就会通过引用通知观察者
									* 2|[[Logseq元知识库/pages/发布订阅模式\|发布订阅模式]]比[[Logseq元知识库/pages/观察者模式\|观察者模式]]多引入了一个中间角色，叫Broker，从而彻底解耦了观察者和被观察者以至于被观察者并不需要知道观察者的任何信息)。[[Logseq元知识库/pages/发布订阅模式\|发布订阅模式]]，可以是跨应用的模式，比如[[Logseq元知识库/pages/消息队列\|消息队列]]采用的[[Logseq元问题库/pages/？发布订阅模型\|？发布订阅模型]] ，而[[Logseq元知识库/pages/观察者模式\|观察者模式]]只能是单应用的模式
					    * 1|[[Logseq元知识库/pages/事件驱动\|事件驱动]]的常见[[Logseq元知识库/pages/事件\|事件]]组件的概念：[[Logseq元知识库/pages/事件处理器\|事件处理器]] [[Logseq元知识库/pages/事件监听器\|事件监听器]] [[Logseq元知识库/pages/事件循环\|事件循环]] [[Logseq元知识库/pages/事件收集器\|事件收集器]]。在实际实现中，可能不是按这么分着实现的，但这些概念代表了[[Logseq元知识库/pages/事件驱动\|事件驱动]]的重要环节。
						    * [[Logseq元知识库/pages/事件\|事件]]
							    * 事件是指发生在程序运行过程中的某些特定情况，如用户点击鼠标、按下键盘、网络数据到达等。事件通常包含了[[Logseq元知识库/pages/事件源\|事件源]]和[[Logseq元知识库/pages/事件类型\|事件类型]]两个属性，用于标识事件的来源和性质。 
						    * [[Logseq元知识库/pages/事件处理器\|事件处理器]]
							    * [[Logseq元知识库/pages/事件处理器\|事件处理器]] 是指响应[[Logseq元知识库/pages/事件\|事件]]的程序代码，它定义了当某种类型的事件发生时，应该执行的操作。通常是一个函数或者一个对象的方法，它接收一个事件对象作为参数，并根据事件的内容进行相应的处理 
						    * [[Logseq元知识库/pages/事件监听器\|事件监听器]]
							    * [[Logseq元知识库/pages/事件监听器\|事件监听器]]是指注册到[[Logseq元知识库/pages/事件源\|事件源]]上的对象，它负责监听[[Logseq元知识库/pages/事件源\|事件源]]上发生的事件，并将其转发给相应的[[Logseq元知识库/pages/事件处理器\|事件处理器]]。[[Logseq元知识库/pages/事件监听器\|事件监听器]]可以是一个函数或者一个对象，它实现了一个特定的接口或者继承了一个特定的类，用于定义如何监听和转发事件。
						    * [[Logseq元知识库/pages/事件循环\|事件循环]]
							    * [[Logseq元知识库/pages/事件循环\|事件循环]]是指一个程序结构，用于等待和分发消息和事件。[[Logseq元知识库/pages/事件循环\|事件循环]]通常运行在一个单独的线程中，它不断地从一个或多个[[Logseq元知识库/pages/事件源\|事件源]]获取事件，并将其交给相应的[[Logseq元知识库/pages/事件监听器\|事件监听器]] 和[[Logseq元知识库/pages/事件处理器\|事件处理器]] 。事件循环可以使用操作系统提供的[[Logseq元知识库/pages/IO多路复用\|IO多路复用]]机制来实现高效的事件检测和分发 
								    * [[Logseq元知识库/pages/IO多路复用\|IO多路复用]]
									    * 多个连接共用一个阻塞对象，应用程序只需要在一个阻塞对象上等待，无需阻塞等待所有连接，当某条连接有数据到达时，操作系统会通知应用程序，执行线程就会从阻塞状态返回，开始业务处理。由此可见，[[Logseq元知识库/pages/IO多路复用\|IO多路复用]]其实底层是操作系统提供的一种[[Logseq元知识库/pages/事件驱动\|事件驱动]]机制
						    
						    * [[Logseq元知识库/pages/事件收集器\|事件收集器]]
							    * 事件收集器是指一个负责收集和存储事件的组件，它可以是一个数据库、一个消息队列、一个日志文件等。事件收集器可以用于记录事件的历史，或者将事件转发给其他的事件处理器或监听器。
					    * 2|![Pasted image 20230728160926.png](/img/user/Logseq%E5%85%83%E9%97%AE%E9%A2%98%E5%BA%93/assets/Pasted%20image%2020230728160926.png)
						    * 在上图中事件生产者就是[[Logseq元知识库/pages/事件源\|事件源]]，[[Logseq元知识库/pages/事件处理器\|事件处理器]] 就是事件消费者，[[Logseq元知识库/pages/事件收集器\|事件收集器]]是可选的，不过就算没有[[Logseq元知识库/pages/事件收集器\|事件收集器]]，在事件生产者和事件处理器之间也需要一些起到获取事件并分发事件的组件，事件生产者和事件消费者照样是彻底解耦的。
				    	* 3|[[Logseq元知识库/pages/事件驱动\|事件驱动]]||[[Logseq元知识库/pages/发布订阅模式\|发布订阅模式]]
					    	* [[Logseq元知识库/pages/事件驱动\|事件驱动]] 和[[Logseq元知识库/pages/发布订阅模式\|发布订阅模式]]本质上基本相同，以至于我们可以这样类比： [[Logseq元知识库/pages/事件源\|事件源]] <-> [[Logseq元知识库/pages/生产者\|生产者]] [[Logseq元知识库/pages/事件收集器\|事件收集器]] <-> [[Logseq元知识库/pages/Broker\|Broker]]，[[Logseq元知识库/pages/事件监听器\|事件监听器]] <->[[Logseq元知识库/pages/消费者\|消费者]] ，[[Logseq元知识库/pages/事件\|事件]] <->消息。他们有差异的地方，在于[[Logseq元知识库/pages/事件驱动\|事件驱动]]更加关注事件的语义和事件处理逻辑，而[[Logseq元知识库/pages/发布订阅模式\|发布订阅模式]]更加关注消息的传递，不关心消息的含义，也不关心消息是如何被消费的话 
					* 1|[[Logseq元知识库/pages/事件驱动架构\|事件驱动架构]]的思路是运用[[Logseq元知识库/pages/事件驱动\|事件驱动]] ，即定义一系列的事件处理器来响应事件的发生，并且将服务端接收连接与对事件的处理分离。其中，事件是一种状态的改变。比如，tcp中socket的new incoming connection、ready for read、ready for. write。
						* [[Logseq元知识库/pages/Acceptor\|Acceptor]]
							* [[Logseq元知识库/pages/事件驱动架构\|事件驱动架构]]中负责接受客户端的连接请求，并创建相应的[[Logseq元知识库/pages/Handler\|Handler]]来处理后续的[[Logseq元知识库/pages/事件\|事件]]
						* [[Logseq元知识库/pages/Handler\|Handler]]
							* [[Logseq元知识库/pages/事件驱动架构\|事件驱动架构]]中负责处理客户端连接后的各种网络[[Logseq元知识库/pages/IO\|IO]]事件，是一个[[Logseq元知识库/pages/事件处理器\|事件处理器]]
		* 3|[[Logseq元知识库/pages/Reactor模式\|Reactor模式]]
			* 是一种应用在服务器端的、充分利用了[[Logseq元知识库/pages/IO多路复用\|IO多路复用]]的[[Logseq元知识库/pages/事件驱动架构\|事件驱动架构]] 的实现模式。它的关键在于[[Logseq元知识库/pages/Reactor\|Reactor]]
				* [[Logseq元知识库/pages/Reactor\|Reactor]]
					* 0|是[[Logseq元知识库/pages/Reactor模式\|Reactor模式]]的核心组件，它有以下主要职责：
						* 0|管理[[Logseq元知识库/pages/事件源\|事件源]]：[[Logseq元知识库/pages/事件源\|事件源]]是指可以产生[[Logseq元知识库/pages/事件\|事件]]的对象，如[[Logseq元知识库/pages/Socket⁰\|Socket⁰]] 、文件、定时器等。[[Logseq元知识库/pages/Reactor\|Reactor]]组件需要维护一个或多个事件源的集合，并将它们注册到操作系统提供的[[Logseq元知识库/pages/IO多路复用\|IO多路复用]] 机制中，如 #select模型 #epoll模型 #poll模型 
						- 监听[[Logseq元知识库/pages/事件\|事件]]：[[Logseq元知识库/pages/Reactor\|Reactor]]组件需要调用[[Logseq元知识库/pages/IO多路复用\|IO多路复用]]机制来阻塞等待[[Logseq元知识库/pages/事件\|事件]]的发生，并获取发生[[Logseq元知识库/pages/事件\|事件]]的[[Logseq元知识库/pages/事件源\|事件源]]和事件类型。
						- 分发事件：当[[Logseq元知识库/pages/Reactor\|Reactor]]组件检测到[[Logseq元知识库/pages/事件\|事件]]发生后，它需要根据[[Logseq元知识库/pages/事件源\|事件源]]和事件类型来找到相应的[[Logseq元知识库/pages/事件处理器\|事件处理器]]，并将[[Logseq元知识库/pages/事件\|事件]]交给该处理器来执行相应的操作。
						- 调度事件：[[Logseq元知识库/pages/Reactor\|Reactor]]组件可以根据不同的策略来调度事件的处理，如同步或异步、串行或并行、优先级或轮询等。Reactor组件可以根据系统的性能和需求来选择合适的调度方式。
				- 还有以下三种细分模式：
					- [[Logseq元知识库/pages/Reactor单线程模型\|Reactor单线程模型]]
						-  0|![Pasted image 20230730204945.png](/img/user/Logseq%E5%85%83%E9%97%AE%E9%A2%98%E5%BA%93/assets/Pasted%20image%2020230730204945.png)
							* [[ Reactor\| Reactor]]对象通过 Select行为获取到由[[Logseq元知识库/pages/IO多路复用\|IO多路复用]] 监听到的客户端请求事件，收到事件后通过 Dispatch行为进行分发；
							- 如果是建立连接请求事件，则由 #Acceptor 处理连接请求，然后创建一个 #Handler  对象处理连接完成后的后续业务处理 
							- 如果不是建立连接事件，则[[Logseq元知识库/pages/Reactor\|Reactor]]会分发调用连接对应的[[Logseq元知识库/pages/Handler\|Handler]]来响应
							- [[Logseq元知识库/pages/Handler\|Handler]]会完成Read→业务处理→Send 的完整业务流程
							- 以上组件和流程全部在一个线程完成
						- 1|优点
							- 模型简单，没有多线程、进程通信、竞争的问题，全部都在一个线程中完成 
						- 2|缺点 
							- 性能问题，只有一个线程，无法完全发挥多核 CPU 的性能。Handler 在处理某个连接上的业务时，整个进程无法处理其他连接事件，很容易导致性能瓶颈
						- 3|使用场景
							- 客户端的数量有限，业务处理非常快速，比如[[Logseq元知识库/pages/Redis\|Redis]]，业务处理的时间复杂度 O(1)
					- [[Logseq元知识库/pages/Reactor多线程模型\|Reactor多线程模型]]
						- 0|![Pasted image 20230730205116.png](/img/user/Logseq%E5%85%83%E9%97%AE%E9%A2%98%E5%BA%93/assets/Pasted%20image%2020230730205116.png)
							- 前面3步同 #Reactor单线程模型
							- [[Logseq元知识库/pages/Handler\|Handler]] 只负责响应事件，不做具体业务处理，通过 Read 读取数据后，会分发给后面的 Worker 线程池进行业务处理
							- Worker 线程池会分配独立的线程完成真正的业务处理，如何将响应结果发给 #Handler 进行处理
							- [[Logseq元知识库/pages/Handler\|Handler]]收到响应结果后通过 Send 将响应结果返回给 Client
						- 1|优点 
							- 可以充分利用多核 CPU 的处理能力
						- 2|缺点 
							- 多线程数据共享和访问比较复杂；[[Logseq元知识库/pages/Reactor\|Reactor]] 承担所有事件的监听和响应，且在单线程中运行，高并发场景下容易成为性能瓶颈。
					- [[Logseq元知识库/pages/Reactor主从线程模型\|Reactor主从线程模型]]
						- ![Pasted image 20230730205042.png](/img/user/Logseq%E5%85%83%E9%97%AE%E9%A2%98%E5%BA%93/assets/Pasted%20image%2020230730205042.png)
							- [[Logseq元知识库/pages/Reactor\|Reactor]]主线程[[Logseq元知识库/pages/MainReactor\|MainReactor]]对象通过Select行为获取到由[IO多路复用](app://obsidian.md/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8) 监听到的客户端请求事件，收到连接事件后Dispatch给[[Logseq元知识库/pages/Acceptor\|Acceptor]]，处理建立连接事件
							- [[Logseq元知识库/pages/Acceptor\|Acceptor]]处理建立连接事件后，[[Logseq元知识库/pages/MainReactor\|MainReactor]]将连接分配[[Logseq元知识库/pages/Reactor\|Reactor]]子线程给[[Logseq元知识库/pages/SubReactor\|SubReactor]]进行处理 
							- [[Logseq元知识库/pages/SubReactor\|SubReactor]]将连接加入连接队列进行监听，并创建一个 #Handler 用于处理各种连接事件
							- 当有新的事件发生时，[[Logseq元知识库/pages/SubReactor\|SubReactor]]会调用连接对应的 #Handler 进行响应 
							- [[Logseq元知识库/pages/Handler\|Handler]]通过 Read 读取数据后，会分发给后面的 Worker 线程池进行业务处理
							- Worker线程池会分配独立的线程完成真正的业务处理，然后将响应结果发给 #Handler 进行处理
							- [[Logseq元知识库/pages/Handler\|Handler]]收到响应结果后通过 Send 将响应结果返回给 Client
						- 优点 
							- 父线程与子线程的数据交互简单职责明确，父线程只需要接收新连接，子线程完成后续的业务处理。 父线程与子线程的数据交互简单，Reactor 主线程只需要把新连接传给子线程，子线程无需返回数据。 这种模型在许多项目中广泛使用，包括 Nginx 主从 Reactor 多进程模型，Memcached 主从多线程，  #Netty  主从多线程模型的支持。
		*  4|[[Logseq元知识库/pages/Netty\|Netty]] 支持三种线程模型(通过bootstrap.group()方法来设置)
			*  [[Logseq元知识库/pages/Reactor单线程模型\|Reactor单线程模型]]
				* 4|用[[Logseq元知识库/pages/Netty\|Netty]]完成[[Logseq元知识库/pages/Reactor多线程模型\|Reactor多线程模型]]代码示例 
					* bootstrap.group(new NioEventLoopGroup(1));  //[[Logseq元问题库/pages/？？Netty代码示例\|？？Netty代码示例]]
			* [[Logseq元知识库/pages/Reactor多线程模型\|Reactor多线程模型]]
				* 3||用[[Logseq元知识库/pages/Netty\|Netty]]完成[[Logseq元知识库/pages/Reactor多线程模型\|Reactor多线程模型]]代码示例 
					* bootstrap.group(new NioEventLoopGroup(1), new NioEventLoopGroup())//[[Logseq元问题库/pages/？？Netty代码示例\|？？Netty代码示例]]
			* [[Logseq元知识库/pages/Reactor主从线程模型\|Reactor主从线程模型]]
    			*  3||用[[Logseq元知识库/pages/Netty\|Netty]]完成[[Logseq元知识库/pages/Reactor多线程模型\|Reactor多线程模型]]代码示例
					* bootstrap.group(new NioEventLoopGroup(2), new NioEventLoopGroup() );//[[Logseq元问题库/pages/？？Netty代码示例\|？？Netty代码示例]]
	* [[卡片/P119.61、Netty的高性能体现在哪些方面\|P119.61、Netty的高性能体现在哪些方面]]
		* [00:00](http://localhost:5244/d/%E6%88%91%E7%9A%84%E5%BA%A6%E7%9B%98/%E8%A7%86%E9%A2%91/%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9-%E8%8A%B1%E4%BA%86%E4%B8%A4%E4%B8%87%E4%B9%B0%E7%9A%84Java%E9%9D%A2%E8%AF%95%E5%90%88%E9%9B%86-%E5%91%A8%E7%91%9C%E8%80%81%E5%B8%88/P119.61%E3%80%81Netty%E7%9A%84%E9%AB%98%E6%80%A7%E8%83%BD%E4%BD%93%E7%8E%B0%E5%9C%A8%E5%93%AA%E4%BA%9B%E6%96%B9%E9%9D%A2.mp4#t=0)
			* [[Logseq元问题库/pages/？Netty 高性能\|？Netty 高性能]]
				* 0|使用 #AIO 有效应对高并发场景，避免了[[Logseq元知识库/pages/BIO\|BIO]] 导致的线程阻塞和资源浪费
				* 1|采用 #Reactor模式 ，分离了监听线程和IO线程，充分利用多核 CPU 的处理能力，提高了网络的读写效率和并行处理能力
				* 2|实现了 #零拷贝 技术，从而可以高效率的传输文件数据
				* 3|消息的[[Logseq元知识库/pages/串行化处理\|串行化处理]]即消息的处理尽可能在同一个线程中完成，期间不进行线程切换，这样就避免了多线程竞争和同步锁，表面上看，这种设计似乎CPU利用率低，并发度不够，但是通过调整NIO线程池的线程参数，可以同时启动多个串行化的线程并行运行，这种局部无锁化的串行化设计在高竞争的场景下反而比一个队里多个工作线程模型性能更优
				* 4|高性能序列化协议：支持 #Protobuf 等高性能序列化协议
				* 5|高效并发编程的体现：volatile的大量正确使用；CAS和原子类的广泛使；线程安全容器的使用，通过读写锁提升并发性能
	* [[卡片/P120.62、Redis有哪些数据结构？分别有哪些典型的应用场景？\|P120.62、Redis有哪些数据结构？分别有哪些典型的应用场景？]]
		* [00:00](http://localhost:5244/d/%E6%88%91%E7%9A%84%E5%BA%A6%E7%9B%98/%E8%A7%86%E9%A2%91/%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9-%E8%8A%B1%E4%BA%86%E4%B8%A4%E4%B8%87%E4%B9%B0%E7%9A%84Java%E9%9D%A2%E8%AF%95%E5%90%88%E9%9B%86-%E5%91%A8%E7%91%9C%E8%80%81%E5%B8%88/P120.62%E3%80%81Redis%E6%9C%89%E5%93%AA%E4%BA%9B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%EF%BC%9F%E5%88%86%E5%88%AB%E6%9C%89%E5%93%AA%E4%BA%9B%E5%85%B8%E5%9E%8B%E7%9A%84%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%EF%BC%9F.mp4#t=0)
		* [简悦 | 你真的懂 Redis 的 5 种基本数据结构吗？](http://localhost:7026/unread/10)
		* [简悦 | Redis 数据结构 _ 小林 coding](http://localhost:7026/unread/12)
		* [简悦 | Redis 常见数据类型和应用场景 _ 小林 coding](http://localhost:7026/unread/11)
				* [[Logseq元知识库/pages/Redis\|Redis]]是一个开源的，基于内存的高性能的 #key-value 数据库。
				* [[Logseq元问题库/pages/？Redis数据结构\|？Redis数据结构]]从最顶层看就是个 #key-value 集合 ，这一点可以从 #Redis 的对外Api就可以看出，更准确的说是个 #哈希表 。其中的键始终是字符串，而值则是五种数据类型的[[Logseq元知识库/pages/Redis对象\|Redis对象]]： [[Logseq元知识库/pages/Redis字符串\|Redis字符串]] , [[Logseq元知识库/pages/Redis哈希表\|Redis哈希表]] ， [[Logseq元知识库/pages/Redis列表\|Redis列表]]  ， [[Redis集合 \|Redis集合 ]]， [[Logseq元知识库/pages/Redis有序集合\|Redis有序集合]]
				* [[Logseq元知识库/pages/Redis字符串\|Redis字符串]]类型的值可以是字符串、整数或者浮点数。[[Logseq元知识库/pages/Redis字符串\|Redis字符串]]的应用场景：可以用来做最简单的缓存，如可以缓存某个简单的字符串，也可以缓存某个对象的json字符串，实现[[Logseq元知识库/pages/Redis分布式锁\|Redis分布式锁]]，还包括可以实现[[Logseq元知识库/pages/计数器\|计数器]]、[[Logseq元知识库/pages/Session共享\|Session共享]]、[[Logseq元知识库/pages/分布式id\|分布式id]]
				* [[Logseq元知识库/pages/Redis哈希表\|Redis哈希表]]类型的值是一个 #键值  #哈希表 。[[Logseq元知识库/pages/Redis哈希表\|Redis哈希表]]的应用场景：比 [[Logseq元知识库/pages/Redis字符串\|Redis字符串]] 更适合用来存储对象。
				* [[Logseq元知识库/pages/Redis列表\|Redis列表]]类型的值是一个 #Redis字符串 #链表 。[[Logseq元知识库/pages/Redis列表\|Redis列表]]的应用场景：通过命令的组合，可以当作队列使用，可以用来缓存类似微信公众号、微博等消息流的数据
				* [[Logseq元知识库/pages/Redis集合\|Redis集合]]类型的值是一个无序不重复的 #Redis字符串 集合。[[Logseq元知识库/pages/Redis集合\|Redis集合]]的应用场景：通过集合的交集、并集、差集等操作，可以实现如共同好友、共同关注等功能
				* [[Logseq元知识库/pages/Redis有序集合\|Redis有序集合]]类型的值是一个可设置顺序的 #Redis字符串 的 不重复集合。[[Logseq元知识库/pages/Redis有序集合\|Redis有序集合]]的应用场景：通过设置顺序，可以用来实现排行榜功能
	* [[卡片/P121.63、Redis分布式锁底层是如何实现的？\|P121.63、Redis分布式锁底层是如何实现的？]]
		* [00:00](http://localhost:5244/d/%E6%88%91%E7%9A%84%E5%BA%A6%E7%9B%98/%E8%A7%86%E9%A2%91/%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9-%E8%8A%B1%E4%BA%86%E4%B8%A4%E4%B8%87%E4%B9%B0%E7%9A%84Java%E9%9D%A2%E8%AF%95%E5%90%88%E9%9B%86-%E5%91%A8%E7%91%9C%E8%80%81%E5%B8%88/P121.63%E3%80%81Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%BA%95%E5%B1%82%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E7%9A%84%EF%BC%9F.mp4#t=0.142346)
		* [[Logseq元知识库/pages/Redis分布式锁\|Redis分布式锁]]的实现
		    * [简悦 | java - Redis 分布式锁的正确实现原理演化历程与 Redission 实战总结 - Redis - SegmentFault 思否](http://localhost:7026/unread/13)
    		* 第一、利用setnx设置一个 #Redis字符串 ：如果key不存在，则设置key的值为value，返回1，代表获取锁成功；如果key已经存在，则返回0，代表获取不到锁。
    		* 第二、要考虑到锁的释放：要通过Del主动释放锁，以在业务处理完成后，其他线程可以获取锁；其次，要设置锁的expire时间，以防止业务处理失败或节点宕机等情况导致锁无法释放，造成死锁
    		* 第三、value应该要设置含有线程专属标识的值，以在主动释放锁时可以Get检查value是否是线程专属接着再Del，避免释放别人的锁。释放别人的锁的场景：线程A获取锁后业务处理时间过长时，于是锁失效，其他线程获取到锁，这时线程A终于处理完了主动释放锁，就把其他线程的锁给释放了
    		* 第四、还要利用lua脚本来保证第三步的Get-Del的redis操作的原子性，否则如果Get之后立马就有其他线程获取到锁，这时候Del就会把其他线程的锁给释放了
    		* 第五、如有需要，还要考虑到锁的可重入性，这一点可以将上面的[[Logseq元知识库/pages/Redis字符串\|Redis字符串]]改为[[Logseq元知识库/pages/Redis哈希表\|Redis哈希表]]来记录重入次数
    		* 第六、如有需要，需考虑 #Redis 节点宕机的情况，所以要采用[[Logseq元知识库/pages/红锁\|红锁]]的方式同时向N/2+1个节点申请锁，都申请到了才证明获取锁成功，这样就算其中一个节点宕机了，也能保证锁的可用性，同时也能保证获取后其他线程不可能再获取到锁（因为N/2+1个节点都已被锁定，其他节点肯定无法获得超过N/2+1个节点的共识）
	* [[卡片/P122.64、Redis主从复制的核心原理\|P122.64、Redis主从复制的核心原理]]
		* [00:00](http://localhost:5244/d/%E6%88%91%E7%9A%84%E5%BA%A6%E7%9B%98/%E8%A7%86%E9%A2%91/%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9-%E8%8A%B1%E4%BA%86%E4%B8%A4%E4%B8%87%E4%B9%B0%E7%9A%84Java%E9%9D%A2%E8%AF%95%E5%90%88%E9%9B%86-%E5%91%A8%E7%91%9C%E8%80%81%E5%B8%88/P122.64%E3%80%81Redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E7%9A%84%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86.mp4#t=0)
		* [简悦 | 彻底搞懂 Redis 主从复制机制](http://localhost:7026/unread/14)
		* [[Logseq元知识库/pages/Redis主从复制\|Redis主从复制]]分为全量复制和部分复制。在 Redis2.8 以前，从节点向主节点发送 sync 命令请求同步数据，此时的同步方式是全量复制；在 Redis2.8 及以后，从节点可以发送 psync 命令请求同步数据，此时根据主从节点当前状态的不同，同步方式可能是全量复制或部分复制。
		* psync命令的格式psync {runid} {offset} 
			* runid是主节点的运行id，offset是从节点的复制偏移量
		* [[Logseq元知识库/pages/Redis主从复制\|Redis主从复制]]的原理
    		* Redis 2.8以后 
        		* 集群启动时，从节点通过slaveof命令连接到主节点后，会进行一些判断以决定接下来是全量复制还是部分复制
    			* 全量复制基于[[Logseq元知识库/pages/RDB\|RDB]]，流程如下：
        			* 如果从节点之前没有复制过任何节点，或是之前执行过slaveof no one命令即脱离过slave状态，则从节点就会向主节点发送psync ？ -1即全量复制请求
        			* 主节点收到全量复制的命令后，执行 bgsave，在后台生成 RDB 文件，并使用一个缓冲区（称为复制缓冲区）记录从现在开始执行的所有写命令
        			* 主节点的 bgsave 执行完成后，将 RDB 文件发送给从节点；从节点首先清除自己的旧数据，然后载入接收的 RDB 文件，将数据库状态更新至主节点执行 bgsave 时的数据库状态
        			* 主节点将前述复制缓冲区中的所有写命令发送给从节点，从节点执行这些写命令，将数据库状态更新至主节点的最新状态。
        			* 如果从节点开启了 AOF，则会触发 bgrewriteaof 的执行，从而保证 AOF 文件更新至主节点的最新状态
      			* 部分复制基于[[Logseq元知识库/pages/AOF\|AOF]]，流程如下：
        			* 如果前面从节点已经同步过部分数据，此时从节点就会发送 psync {runid} {offset} 命令给主节点。其中offset指向主节点[[Logseq元知识库/pages/AOF\|AOF]]日志中从节点最后一次同步到的位置
	                	* 主节点根据offset，从AOF文件中读取相应的写命令，发送给从节点。如果主节点没有[[Logseq元知识库/pages/AOF\|AOF]]日志，或者AOF日志中没有从节点所需命令，那么就会执行全量复制
	* [[卡片/P123.65、缓存穿透、缓存击穿、缓存雪崩分别是什么\|P123.65、缓存穿透、缓存击穿、缓存雪崩分别是什么]]
		* [00:00](http://localhost:5244/d/%E6%88%91%E7%9A%84%E5%BA%A6%E7%9B%98/%E8%A7%86%E9%A2%91/%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9-%E8%8A%B1%E4%BA%86%E4%B8%A4%E4%B8%87%E4%B9%B0%E7%9A%84Java%E9%9D%A2%E8%AF%95%E5%90%88%E9%9B%86-%E5%91%A8%E7%91%9C%E8%80%81%E5%B8%88/P123.65%E3%80%81%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E3%80%81%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF%E3%80%81%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E5%88%86%E5%88%AB%E6%98%AF%E4%BB%80%E4%B9%88.mp4#t=0)
		* [[Logseq元知识库/pages/缓存穿透\|缓存穿透]]
		* [[Logseq元知识库/pages/缓存击穿\|缓存击穿]]
		* [[Logseq元知识库/pages/缓存雪崩\|缓存雪崩]]
	* [[卡片/P124.66、Redis和Mysql如何保证数据一致\|P124.66、Redis和Mysql如何保证数据一致]]
		* [00:00](http://localhost:5244/d/%E6%88%91%E7%9A%84%E5%BA%A6%E7%9B%98/%E8%A7%86%E9%A2%91/%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9-%E8%8A%B1%E4%BA%86%E4%B8%A4%E4%B8%87%E4%B9%B0%E7%9A%84Java%E9%9D%A2%E8%AF%95%E5%90%88%E9%9B%86-%E5%91%A8%E7%91%9C%E8%80%81%E5%B8%88/P124.66%E3%80%81Redis%E5%92%8CMysql%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4.mp4#t=0)
		* [[Logseq元问题库/pages/Redis 同步 数据库\|Redis 同步 数据库]]
			* 以 #Mysql 为例
				* 1、先更新 #MySQL ，再更新 #Redis，如果更新 #Redis 失败，两者数据仍未同步到一致
				* 2、先删除 #Redis缓存数据 ，再更新 #MySQL ，再次查询的时候将更新后的数据添加到缓存中，可以解决方案1的问题，但是因为操作成本高故在高并发场景性能较低，且仍会出现数据不一致的问题，比如线程1删除了 #Redis 缓存数据，正在更新 #Mysql ，此时另外一个线程再查询，就会把老数据又加到缓存中
				* 3、延时双删，步骤是：先删Redis缓存数据，再更新 #Mysql ，延迟几百毫秒再删除Redis缓存数据，这样就算在更新 #Mysql 期间有线程查询，把老数据加到缓存中，也会在延迟时间内被删除，从而保证了数据一致性
	* [[卡片/P125.67、Explain语句结果中各个字段分表表示什么\|P125.67、Explain语句结果中各个字段分表表示什么]]
		* [00:00](http://localhost:5244/d/%E6%88%91%E7%9A%84%E5%BA%A6%E7%9B%98/%E8%A7%86%E9%A2%91/%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9-%E8%8A%B1%E4%BA%86%E4%B8%A4%E4%B8%87%E4%B9%B0%E7%9A%84Java%E9%9D%A2%E8%AF%95%E5%90%88%E9%9B%86-%E5%91%A8%E7%91%9C%E8%80%81%E5%B8%88/P125.67%E3%80%81Explain%E8%AF%AD%E5%8F%A5%E7%BB%93%E6%9E%9C%E4%B8%AD%E5%90%84%E4%B8%AA%E5%AD%97%E6%AE%B5%E5%88%86%E8%A1%A8%E8%A1%A8%E7%A4%BA%E4%BB%80%E4%B9%88.mp4#t=0)
		* [[Logseq元知识库/pages/Explain语句\|Explain语句]]的各个字段如下: 
			* 
			  | 列名          | 描述                                                                                                         |
			  | ------------- | ------------------------------------------------------------------------------------------------------------ |
			  | id            | 表示查询步骤的唯一标识，数字越大越先执行；相同id的行按照从上到下的顺序执行。                                 |
			  | select_type   | 表示查询类型，常见的有SIMPLE（简单查询）、PRIMARY（最外层查询）、SUBQUERY（子查询）、DERIVED（派生表查询）等 |
			  | table         | 表示当前行访问的表名，如果表有别名，则显示别名。                                                             |
			  | partitions    | 表示当前查询匹配的分区，如果表没有分区，则显示null                                                           |
			  | possible_keys | 表示可能用到的索引，不一定实际使用了                                                                         |
			  | key           | 示实际使用的索引，如果为null，则表示没有使用索引                                                             |
			  | key_len       | 表示实际使用的索引长度，单位是字节。索引长度越短，效率越高                                                   |
			  | ref           | 当使用索引列等值查询时，与索引列进行等值匹配的对象信息                                                       |
			  | rows          | 表示MySQL估计要读取的行数，不一定准确，但可以作为判断查询效率的参考                                          |
			  | filtered      | 表示按照表条件过滤后剩余的记录百分比，越高越好                                                            |
			  |Extra               |表示MySQL对查询的额外信息，比如是否使用了临时表、是否排序、是否去重等。这个字段很重要，可以帮助我们发现一些潜在的性能问题                                                                                                              |
	* [[卡片/P126.68、索引覆盖是什么\|P126.68、索引覆盖是什么]]
		* [00:00](http://localhost:5244/d/%E6%88%91%E7%9A%84%E5%BA%A6%E7%9B%98/%E8%A7%86%E9%A2%91/%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9-%E8%8A%B1%E4%BA%86%E4%B8%A4%E4%B8%87%E4%B9%B0%E7%9A%84Java%E9%9D%A2%E8%AF%95%E5%90%88%E9%9B%86-%E5%91%A8%E7%91%9C%E8%80%81%E5%B8%88/P126.68%E3%80%81%E7%B4%A2%E5%BC%95%E8%A6%86%E7%9B%96%E6%98%AF%E4%BB%80%E4%B9%88.mp4#t=0)
		* [[Logseq元知识库/pages/索引覆盖\|索引覆盖]]是指一个查询语句在执行过程中，只通过索引就能获取到查询所需的数据，而不需要再通过回表查询数据行，从而提高查询效率。比如有一个商品表product，包含id（主键）、name、price、category、stock等字段，其中price和category有一个联合索引（price,category），那么select name, price from product where name = '华为nova5' order by price desc limit 1这条mysql查询就会出现索引覆盖，因为构成联合索引的字段同时也是要查询的字段，因此找到了索引就找到了数据，没必要通过索引记录的主键回主键 #B⨥树 再去查询数据行
	* [[卡片/P127.69、最左前缀原则是什么\|P127.69、最左前缀原则是什么]]
		* [00:00](http://localhost:5244/d/%E6%88%91%E7%9A%84%E5%BA%A6%E7%9B%98/%E8%A7%86%E9%A2%91/%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9-%E8%8A%B1%E4%BA%86%E4%B8%A4%E4%B8%87%E4%B9%B0%E7%9A%84Java%E9%9D%A2%E8%AF%95%E5%90%88%E9%9B%86-%E5%91%A8%E7%91%9C%E8%80%81%E5%B8%88/P127.69%E3%80%81%E6%9C%80%E5%B7%A6%E5%89%8D%E7%BC%80%E5%8E%9F%E5%88%99%E6%98%AF%E4%BB%80%E4%B9%88.mp4#t=0)
		* [[Logseq元知识库/pages/最左前缀原则\|最左前缀原则]]是指在使用联合索引（复合索引）进行查询时，查询条件需要遵循索引中列的顺序，从左到右进行匹配。联合索引是指在一个表中创建一个包含多个列的索引，可以提高查询效率。最左前缀原则的原理是基于 #B⨥树  的索引结构，因为 #B⨥树  是按照索引列的顺序从左到右进行排序和查找的。
## ✏想

## ✏识